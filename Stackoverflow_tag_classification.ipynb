{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(os.getcwd(), 'stack_overflow_16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'java', 'csharp', 'javascript']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory('stack_overflow_16k/train',batch_size = batch_size, validation_split = 0.2, subset = 'training', seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review b'\"my tester is going to the wrong constructor i am new to programming so if i ask a question that can be easily fixed, please forgive me. my program has a tester class with a main. when i send that to my regularpolygon class, it sends it to the wrong constructor. i have two constructors. 1 without perameters..public regularpolygon().    {.       mynumsides = 5;.       mysidelength = 30;.    }//end default constructor...and my second, with perameters. ..public regularpolygon(int numsides, double sidelength).    {.        mynumsides = numsides;.        mysidelength = sidelength;.    }// end constructor...in my tester class i have these two lines:..regularpolygon shape = new regularpolygon(numsides, sidelength);.        shape.menu();...numsides and sidelength were declared and initialized earlier in the testing class...so what i want to happen, is the tester class sends numsides and sidelength to the second constructor and use it in that class. but it only uses the default constructor, which therefor ruins the whole rest of the program. can somebody help me?..for those of you who want to see more of my code: here you go..public double vertexangle().    {.        system.out.println(\"\"the vertex angle method: \"\" + mynumsides);// prints out 5.        system.out.println(\"\"the vertex angle method: \"\" + mysidelength); // prints out 30..        double vertexangle;.        vertexangle = ((mynumsides - 2.0) / mynumsides) * 180.0;.        return vertexangle;.    }//end method vertexangle..public void menu().{.    system.out.println(mynumsides); // prints out what the user puts in.    system.out.println(mysidelength); // prints out what the user puts in.    gotographic();.    calcr(mynumsides, mysidelength);.    calcr(mynumsides, mysidelength);.    print(); .}// end menu...this is my entire tester class:..public static void main(string[] arg).{.    int numsides;.    double sidelength;.    scanner keyboard = new scanner(system.in);..    system.out.println(\"\"welcome to the regular polygon program!\"\");.    system.out.println();..    system.out.print(\"\"enter the number of sides of the polygon ==&gt; \"\");.    numsides = keyboard.nextint();.    system.out.println();..    system.out.print(\"\"enter the side length of each side ==&gt; \"\");.    sidelength = keyboard.nextdouble();.    system.out.println();..    regularpolygon shape = new regularpolygon(numsides, sidelength);.    shape.menu();.}//end main...for testing it i sent it numsides 4 and sidelength 100.\"\\n'\n",
      "Label 1\n",
      "Review b'\"blank code slow skin detection this code changes the color space to lab and using a threshold finds the skin area of an image. but it\\'s ridiculously slow. i don\\'t know how to make it faster ?    ..from colormath.color_objects import *..def skindetection(img, treshold=80, color=[255,20,147]):..    print img.shape.    res=img.copy().    for x in range(img.shape[0]):.        for y in range(img.shape[1]):.            rgbimg=rgbcolor(img[x,y,0],img[x,y,1],img[x,y,2]).            labimg=rgbimg.convert_to(\\'lab\\', debug=false).            if (labimg.lab_l &gt; treshold):.                res[x,y,:]=color.            else: .                res[x,y,:]=img[x,y,:]..    return res\"\\n'\n",
      "Label 3\n",
      "Review b'\"option and validation in blank i want to add a new option on my system where i want to add two text files, both rental.txt and customer.txt. inside each text are id numbers of the customer, the videotape they need and the price...i want to place it as an option on my code. right now i have:...add customer.rent return.view list.search.exit...i want to add this as my sixth option. say for example i ordered a video, it would display the price and would let me confirm the price and if i am going to buy it or not...here is my current code:..  import blank.io.*;.    import blank.util.arraylist;.    import static blank.lang.system.out;..    public class rentalsystem{.    static bufferedreader input = new bufferedreader(new inputstreamreader(system.in));.    static file file = new file(\"\"file.txt\"\");.    static arraylist&lt;string&gt; list = new arraylist&lt;string&gt;();.    static int rows;..    public static void main(string[] args) throws exception{.        introduction();.        system.out.print(\"\"nn\"\");.        login();.        system.out.print(\"\"nnnnnnnnnnnnnnnnnnnnnn\"\");.        introduction();.        string repeat;.        do{.            loadfile();.            system.out.print(\"\"nwhat do you want to do?nn\"\");.            system.out.print(\"\"n                    - - - - - - - - - - - - - - - - - - - - - - -\"\");.            system.out.print(\"\"nn                    |     1. add customer    |   2. rent return |n\"\");.            system.out.print(\"\"n                    - - - - - - - - - - - - - - - - - - - - - - -\"\");.            system.out.print(\"\"nn                    |     3. view list       |   4. search      |n\"\");.            system.out.print(\"\"n                    - - - - - - - - - - - - - - - - - - - - - - -\"\");.            system.out.print(\"\"nn                                             |   5. exit        |n\"\");.            system.out.print(\"\"n                                              - - - - - - - - - -\"\");.            system.out.print(\"\"nnchoice:\"\");.            int choice = integer.parseint(input.readline());.            switch(choice){.                case 1:.                    writedata();.                    break;.                case 2:.                    rentdata();.                    break;.                case 3:.                    viewlist();.                    break;.                case 4:.                    search();.                    break;.                case 5:.                    system.out.println(\"\"goodbye!\"\");.                    system.exit(0);.                default:.                    system.out.print(\"\"invalid choice: \"\");.                    break;.            }.            system.out.print(\"\"ndo another task? [y/n] \"\");.            repeat = input.readline();.        }while(repeat.equals(\"\"y\"\"));..        if(repeat!=\"\"y\"\") system.out.println(\"\"ngoodbye!\"\");..    }..    public static void writedata() throws exception{.        system.out.print(\"\"nname: \"\");.        string cname = input.readline();.        system.out.print(\"\"address: \"\");.        string add = input.readline();.        system.out.print(\"\"phone no.: \"\");.        string pno = input.readline();.        system.out.print(\"\"rental amount: \"\");.        string ramount = input.readline();.        system.out.print(\"\"tapenumber: \"\");.        string tno = input.readline();.        system.out.print(\"\"title: \"\");.        string title = input.readline();.        system.out.print(\"\"date borrowed: \"\");.        string dborrowed = input.readline();.        system.out.print(\"\"due date: \"\");.        string ddate = input.readline();.        createline(cname, add, pno, ramount,tno, title, dborrowed, ddate);.        rentdata();.    }..    public static void createline(string name, string address, string phone , string rental, string tapenumber, string title, string borrowed, string due) throws exception{.        filewriter fw = new filewriter(file, true);.        fw.write(\"\"nname: \"\"+name + \"\"naddress: \"\" + address +\"\"nphone no.: \"\"+ phone+\"\"nrentalamount: \"\"+rental+\"\"ntape no.: \"\"+ tapenumber+\"\"ntitle: \"\"+ title+\"\"ndate borrowed: \"\"+borrowed +\"\"ndue date: \"\"+ due+\"\":rn\"\");.        fw.close();.    }..    public static void loadfile() throws exception{.        try{.            list.clear();.            fileinputstream fstream = new fileinputstream(file);.            bufferedreader br = new bufferedreader(new inputstreamreader(fstream));.            rows = 0;.            while( br.ready()).            {.                list.add(br.readline());.                rows++;.            }.            br.close();.        } catch(exception e){.            system.out.println(\"\"list not yet loaded.\"\");.        }.    }..    public static void viewlist(){.        system.out.print(\"\"n~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\" |list of all costumers|\"\");.        system.out.print(\"\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        for(int i = 0; i &lt;rows; i++){.            system.out.println(list.get(i));.        }.    }.        public static void rentdata()throws exception.    {   system.out.print(\"\"n~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\" |rent data list|\"\");.        system.out.print(\"\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\"nenter customer name: \"\");.        string cname = input.readline();.        system.out.print(\"\"date borrowed: \"\");.        string dborrowed = input.readline();.        system.out.print(\"\"due date: \"\");.        string ddate = input.readline();.        system.out.print(\"\"return date: \"\");.        string rdate = input.readline();.        system.out.print(\"\"rent amount: \"\");.        string ramount = input.readline();..        system.out.print(\"\"you pay:\"\"+ramount);...    }.    public static void search()throws exception.    {   system.out.print(\"\"n~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\" |search costumers|\"\");.        system.out.print(\"\"~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\"\");.        system.out.print(\"\"nenter costumer name: \"\");.        string cname = input.readline();.        boolean found = false;..        for(int i=0; i &lt; rows; i++){.            string temp[] = list.get(i).split(\"\",\"\");..            if(cname.equals(temp[0])){.            system.out.println(\"\"search result:nyou are \"\" + temp[0] + \"\" from \"\" + temp[1] + \"\".\"\"+ temp[2] + \"\".\"\"+ temp[3] + \"\".\"\"+ temp[4] + \"\".\"\"+ temp[5] + \"\" is \"\" + temp[6] + \"\".\"\"+ temp[7] + \"\" is \"\" + temp[8] + \"\".\"\");.                found = true;.            }.        }..        if(!found){.            system.out.print(\"\"no results.\"\");.        }..    }..        public static boolean evaluate(string uname, string pass){.        if (uname.equals(\"\"admin\"\")&amp;&amp;pass.equals(\"\"12345\"\")) return true;.        else return false;.    }..    public static string login()throws exception{.        bufferedreader input=new bufferedreader(new inputstreamreader(system.in));.        int counter=0;.        do{.            system.out.print(\"\"username:\"\");.            string uname =input.readline();.            system.out.print(\"\"password:\"\");.            string pass =input.readline();..            boolean accept= evaluate(uname,pass);..            if(accept){.                break;.                }else{.                    system.out.println(\"\"incorrect username or password!\"\");.                    counter ++;.                    }.        }while(counter&lt;3);..            if(counter !=3) return \"\"login successful\"\";.            else return \"\"login failed\"\";.            }.        public static void introduction() throws exception{..        system.out.println(\"\"                  - - - - - - - - - - - - - - - - - - - - - - - - -\"\");.        system.out.println(\"\"                  !                  r e n t a l                  !\"\");.        system.out.println(\"\"                   ! ~ ~ ~ ~ ~ !  =================  ! ~ ~ ~ ~ ~ !\"\");.        system.out.println(\"\"                  !                  s y s t e m                  !\"\");.        system.out.println(\"\"                  - - - - - - - - - - - - - - - - - - - - - - - - -\"\");.        }..}\"\\n'\n",
      "Label 1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(\"Review\", text_batch.numpy()[i])\n",
    "        print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to csharp\n",
      "Label 1 corresponds to java\n",
      "Label 2 corresponds to javascript\n",
      "Label 3 corresponds to python\n"
     ]
    }
   ],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])\n",
    "print(\"Label 2 corresponds to\", raw_train_ds.class_names[2])\n",
    "print(\"Label 3 corresponds to\", raw_train_ds.class_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        'stack_overflow_16k/train',\n",
    "        batch_size = batch_size,\n",
    "        validation_split = 0.2,\n",
    "        subset='validation',\n",
    "        seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    'stack_overflow_16k/test', \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]'%re.escape(string.punctuation),'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = TextVectorization(standardize = custom_standardization,\n",
    "                                   max_tokens = max_features,\n",
    "                                   output_mode = 'int',\n",
    "                                   output_sequence_length = sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(b'\"unit testing of setters and getters teacher wanted us to do a comprehensive unit test. for me, this will be the first time that i use junit. i am confused about testing set and get methods. do you think should i test them? if the answer is yes; is this code enough for testing?..  public void testsetandget(){.    int a = 10;.    class firstclass = new class();.    firstclass.setvalue(10);.    int value = firstclass.getvalue();.    assert.asserttrue(\"\"error\"\", value==a);.  }...in my code, i think if there is an error, we can\\'t know that the error is deriving because of setter or getter.\"\\n', shape=(), dtype=string)\n",
      "Label java\n",
      "Vectorized review (<tf.Tensor: shape=(1, 250), dtype=int64, numpy=\n",
      "array([[1011,  773,    9, 2456,    8, 1863, 2362,  690, 1267,    4,   40,\n",
      "           5,    1, 1011,  196,   12,   74,   13,   72,   33,    2,   98,\n",
      "         105,   14,    3,   70, 9611,    3,   34,  888,  202,  773,  107,\n",
      "           8,   41,  242,   40,   58,  291,   90,    3,  196,  191,   10,\n",
      "           2,  182,    6,  668,    6,   13,   30, 1187,   12,  773,   22,\n",
      "          42,    1,   28,    5,  140,   29, 5213,   15,   29,    1,   28,\n",
      "          51,    1,    1,    1,    7,   23,   30,    3,  291,   10,   67,\n",
      "           6,   32,   65,  185,  166,  102,   14,    2,   65,    6,    1,\n",
      "         193,    9, 2784,   45, 2410,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 160,084\n",
      "Trainable params: 160,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(max_features+1, embedding_dim),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(4)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "             optimizer='adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9980 - val_loss: 0.8019 - val_accuracy: 0.8169\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 0.8120 - val_accuracy: 0.8156\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.8099 - val_accuracy: 0.8150\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9987 - val_loss: 0.8235 - val_accuracy: 0.8163\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9984 - val_loss: 0.8293 - val_accuracy: 0.8175\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9981 - val_loss: 0.8295 - val_accuracy: 0.8163\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9983 - val_loss: 0.8320 - val_accuracy: 0.8163\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9981 - val_loss: 0.8389 - val_accuracy: 0.8169\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9981 - val_loss: 0.8436 - val_accuracy: 0.8163\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9989 - val_loss: 0.8493 - val_accuracy: 0.8131\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9992 - val_loss: 0.8517 - val_accuracy: 0.8150\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9981 - val_loss: 0.8586 - val_accuracy: 0.8169\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9989 - val_loss: 0.8658 - val_accuracy: 0.8156\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9983 - val_loss: 0.8663 - val_accuracy: 0.8144\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9987 - val_loss: 0.8760 - val_accuracy: 0.8138\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9983 - val_loss: 0.8721 - val_accuracy: 0.8112\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9986 - val_loss: 0.8790 - val_accuracy: 0.8138\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0148 - accuracy: 0.9987 - val_loss: 0.8887 - val_accuracy: 0.8119\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9992 - val_loss: 0.8933 - val_accuracy: 0.8131\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0153 - accuracy: 0.9983 - val_loss: 0.9012 - val_accuracy: 0.8119\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9991 - val_loss: 0.9028 - val_accuracy: 0.8131\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9986 - val_loss: 0.9121 - val_accuracy: 0.8125\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9991 - val_loss: 0.9113 - val_accuracy: 0.8144\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 0.9190 - val_accuracy: 0.8119\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9994 - val_loss: 0.9194 - val_accuracy: 0.8125\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9994 - val_loss: 0.9234 - val_accuracy: 0.8125\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 0.9290 - val_accuracy: 0.8106\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: 0.9367 - val_accuracy: 0.8131\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0129 - accuracy: 0.9986 - val_loss: 0.9456 - val_accuracy: 0.8144\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9994 - val_loss: 0.9474 - val_accuracy: 0.8150\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9992 - val_loss: 0.9512 - val_accuracy: 0.8094\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.9634 - val_accuracy: 0.8131\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.9599 - val_accuracy: 0.8144\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9994 - val_loss: 0.9614 - val_accuracy: 0.8138\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.9779 - val_accuracy: 0.8112\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 0.9794 - val_accuracy: 0.8094\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9992 - val_loss: 0.9829 - val_accuracy: 0.8119\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.9837 - val_accuracy: 0.8131\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.9903 - val_accuracy: 0.8106\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.9900 - val_accuracy: 0.8112\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 1.0001 - val_accuracy: 0.8069\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.9999 - val_accuracy: 0.8106\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 1.0054 - val_accuracy: 0.8100\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.0135 - val_accuracy: 0.8094\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 1.0120 - val_accuracy: 0.8106\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9997 - val_loss: 1.0241 - val_accuracy: 0.8087\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 1.0206 - val_accuracy: 0.8094\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9997 - val_loss: 1.0254 - val_accuracy: 0.8100\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9995 - val_loss: 1.0338 - val_accuracy: 0.8112\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 1.0431 - val_accuracy: 0.8087\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 1.0383 - val_accuracy: 0.8087\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9994 - val_loss: 1.0500 - val_accuracy: 0.8087\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9998 - val_loss: 1.0514 - val_accuracy: 0.8056\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9995 - val_loss: 1.0519 - val_accuracy: 0.8069\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 1.0619 - val_accuracy: 0.8062\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 1.0578 - val_accuracy: 0.8050\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9998 - val_loss: 1.0634 - val_accuracy: 0.8075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9997 - val_loss: 1.0672 - val_accuracy: 0.8081\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 1.0752 - val_accuracy: 0.8050\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 1.0718 - val_accuracy: 0.8069\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 1.0815 - val_accuracy: 0.8069\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 1.0878 - val_accuracy: 0.8056\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9995 - val_loss: 1.0834 - val_accuracy: 0.8100\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 1.0923 - val_accuracy: 0.8081\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 1.0946 - val_accuracy: 0.8087\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 1.0949 - val_accuracy: 0.8094\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 1.0955 - val_accuracy: 0.8075\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 1.1035 - val_accuracy: 0.8062\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 1.1059 - val_accuracy: 0.8044\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 1.1214 - val_accuracy: 0.8087\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 1.1166 - val_accuracy: 0.8062\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 1.1182 - val_accuracy: 0.8069\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 1.1232 - val_accuracy: 0.8087\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1232 - val_accuracy: 0.8056\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 1.1397 - val_accuracy: 0.8081\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 1.1424 - val_accuracy: 0.8050\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 1.1415 - val_accuracy: 0.8081\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 1.1500 - val_accuracy: 0.8056\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9998 - val_loss: 1.1473 - val_accuracy: 0.8075\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 1.1515 - val_accuracy: 0.8069\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 1.1576 - val_accuracy: 0.8050\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 1.1713 - val_accuracy: 0.8069\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 1.1632 - val_accuracy: 0.8031\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 1.1702 - val_accuracy: 0.8050\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9997 - val_loss: 1.1725 - val_accuracy: 0.8031\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 1.1748 - val_accuracy: 0.8056\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.1761 - val_accuracy: 0.8062\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 1.1933 - val_accuracy: 0.8044\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 1.1881 - val_accuracy: 0.8044\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 1.1894 - val_accuracy: 0.8069\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1950 - val_accuracy: 0.8044\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 1.2146 - val_accuracy: 0.8044\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1998 - val_accuracy: 0.8087\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.8037\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.8044\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 1.2160 - val_accuracy: 0.8031\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.2184 - val_accuracy: 0.8031\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 1.2254 - val_accuracy: 0.8025\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 1.2258 - val_accuracy: 0.8025\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "history = model.fit(train_ds, validation_data = val_ds, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 692us/step - loss: 1.4420 - accuracy: 0.7745\n",
      "Loss:  1.4419821500778198\n",
      "Accuracy:  0.7745000123977661\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
